[["index.html", "R Notebook 1 Prerequisites 1.1 Whats in here? 1.2 For my reference", " R Notebook Peter Kiel modified by Simon Knight and Durand Sinclair 22/08/2019 1 Prerequisites This is a sample book written in Markdown. You can use anything that Pandocs Markdown supports, e.g., a math equation \\(a^2 + b^2 = c^2\\). The bookdown package can be installed from CRAN or Github: #install.packages(&quot;bookdown&quot;) # or the development version # devtools::install_github(&quot;rstudio/bookdown&quot;) library(bookdown) options(bookdown.render.file_scope = FALSE) Remember each Rmd file contains one and only one chapter, and a chapter is defined by the first-level heading #. To compile this example to PDF, you need XeLaTeX. You are recommended to install TinyTeX (which includes XeLaTeX): https://yihui.name/tinytex/. 1.1 Whats in here? There are: Some vignettes (next), two sample AT2 templates, there is also a third but embedding it currently breaks things. And then references. There are learnr packages Ill include at some point. 1.2 For my reference #To preview book use the below #bookdown:::serve_book() "],["preamble.html", "2 Preamble", " 2 Preamble The aim of this file is to show you some basic functionality of an Rmd, and some of the kinds of analysis you might do. Its not intended to be exhaustive, its just to stimulate ideas. "],["some-introductory-functions.html", "3 Some introductory functions 3.1 First, were going to load libraries", " 3 Some introductory functions This is an R Markdown Notebook. When you execute code within the notebook, the results appear beneath the code. Try executing this chunk by clicking the Run button within the chunk or by placing your cursor inside it and pressing Ctrl+Shift+Enter. 3.1 First, were going to load libraries Normally youd hide the code chunk below, but in this instance well keep it there. library(tidyverse) #loads ggplot2, stringr, #Installing tidyverse includes (but won&#39;t load as part of it) readxl, jsonlite, lubridate, httr, rvest, xml2, googlesheets4, library(readxl) library(jsonlite) library(lubridate) library(httr) #these are also useful (in part to demonstrate features) library(psych) library(doBy) library(reshape2) library(lattice) library(scales) library(tidytext) #SimComp lets me create some random datasets with defined properties library(SimComp) #The ones below are specifically for this data library(dslabs) library(trackeR) library(trackeRapp) #library(maptools) #library(revgeo) #So I can embed webpages #install.packages(&quot;webshot&quot;) #webshot::install_phantomjs() library(webshot) Add a new chunk by clicking the Insert Chunk button on the toolbar or by pressing Ctrl+Alt+I. When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the Preview button or press Ctrl+Shift+K to preview the HTML file). The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike Knit, Preview does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed. "],["examples-of-analysing-data-in-r.html", "4 Examples of analysing data in R 4.1 Garmin 4.2 Walking data (and covid impacts) 4.3 Your location 4.4 Text mining demo 4.5 Sentiment on text 4.6 Named entity recognition 4.7 Image processing Images 4.8 EDA and Descriptive Statistics 4.9 Other fun examples", " 4 Examples of analysing data in R These are some example vignettes - worked examples - of how to run a set of analyses in R. You might find some of them useful. You can also explore the examples https://quantifiedself.com/show-and-tell/ and various other sources! Remember, there is no expectation that you code in DSI 36100. There are many many freely available tools that will help you run the kind of basic exploratory statistical analyses you need for AT2 (e.g.Â spreadsheet tools), and visualise data. There are also free tools that will analyse text and images (although possibly not in batch, unless you use an app to collect the images), again without coding. The key thing for this assignment is thinking creatively about how to analyse and make sense of the data and the justification for that, not demonstrating advanced coding skills. Most of the examples below are from MDSI students (a couple from me, and a few externals). You might also find these two posts useful: An Introduction to Accessing RESTful APIs Using R, by Werner Schott, March 31, 2019: In the past, working in R has meant importing data into the application from numerous sources. I have found this very manual and not very reproducible in the development of applications. One of the weaknesses I have identified and would like to address is to understand how to access online data resources using the appropriate packages in R. The scope of this exercise is not to master the use of one package or several packages, but rather understand how certain R packages fit into the overall process, and what that process is. http://rpubs.com/plantagenet/481658 Use R-Studio on any PC (with portable apps), Joshua McCarthy, 29 March 2019, Someone out there has kindly adapted R to the Portable Apps framework! This means we can use R and R-Studio anywhere we like without needing to install R and R-Studio locally, quite handy for work, University computers and VMs. We can also keep all our libraries and packages in one location making them easier to manage when moving between workstations. http://rpubs.com/jsmccid/rportable https://github.com/thomasp85/gganimate - this is very cool, create animated gif visualisations http://r-statistics.co/Top50-Ggplot2-Visualizations-MasterList-R-Code.html - nice examples of a bunch of ggplot charts Create sonified data (using audio to represent the shape of data, as we use visualisation) http://playitbyr.org/ https://cran.r-project.org/web/packages/googleway/vignettes/googleway-vignette.html - connect to a variety of google map based services Corplot is nice, but you probably dont need it for DSI http://rpubs.com/dev_chilwal/481439 Want to visualise your web history? Heres one way to do that https://www.webhistorian.org/education/ Some time ago I saw a blog post on visualising your twitter history using streamgraphs in R. As my tweets moved from mostly psychology/philosophy tweeting around my teaching, through to my current mish-mash of learning analytics stuff, I thought itd be interesting to play with this. So, heres the code reproduced, plus my streamgraph. http://sjgknight.com/finding-knowledge/2016/01/visualising-twitter-history/ 4.1 Garmin #uses the library trackeR. See vignette at https://cran.r-project.org/web/packages/trackeR/vignettes/TourDetrackeR.html - read for detail #First we&#39;re going to load some dummy data. #to do this with your own data, you&#39;ll need to use the function read_container #TO DO THAT YOU SHOULD UNCOMMENT THE FOLLOWING TWO LINES #BUT FOR THE PURPOSES OF THIS DEMO I&#39;M JUST GOING TO IMPORT THE PACKAGE DATA #filepath &lt;- &quot;private/your_Garmin_export.TCX.gz&quot; #runDF &lt;- read_container(filepath, type = &quot;tcx&quot;, timezone = &quot;GMT&quot;) #check other options ################################################## ################################################## knitr::include_url(&quot;http://cran.r-project.org/web/packages/trackeR/vignettes/TourDetrackeR.html&quot;) 4.2 Walking data (and covid impacts) knitr::include_url(&quot;https://methodmatters.github.io/impact-covid-19-pandemic-2020-steps/&quot;) 4.3 Your location knitr::include_url(&quot;https://rpubs.com/Geoff_W/481405&quot;) 4.4 Text mining demo Show some functions basic text stuff. knitr::include_url(&quot;https://rafalab.github.io/dsbook/text-mining.html&quot;) knitr::include_url(&quot;https://cran.r-project.org/web/packages/tidytext/vignettes/tidytext.html&quot;) 4.5 Sentiment on text This is a nicer sentiment analysis package knitr::include_url(&quot;https://cran.r-project.org/web/packages/tidytext/vignettes/tidytext.html&quot;) 4.6 Named entity recognition Can we identify things (people, places, etc.) in text? #I dn&#39;t have storng views on whether this package is the best (the vignette could be expanded a bit...), but it is a tidy approach to NLP and has a nice entity extraction (see entity_type and entity) knitr::include_url(&quot;https://statsmaths.github.io/cleanNLP/state-of-union.html&quot;) #another simple option is entity knitr::include_url(&quot;https://github.com/trinker/entity/blob/master/README.md&quot;) #https://towardsdatascience.com/quick-guide-to-entity-recognition-and-geocoding-with-r-c0a915932895 #Notice they also geocode their data using https://cran.r-project.org/web/packages/tidygeocoder/vignettes/tidygeocoder.html 4.7 Image processing Images Heres a silly example of some functions for dealing with image data, including image recognition knitr::include_url(&quot;https://rpubs.com/sjgknight/food&quot;) 4.8 EDA and Descriptive Statistics Show some 4.9 Other fun examples 4.9.1 search history knitr::include_url(&quot;https://rstudio-pubs-static.s3.amazonaws.com/359000_436aec1332894fe8b4651e1aab587d12.html&quot;) your example here! "],["simplified-very-template-for-dsi-at2.html", "5 Simplified (very) Template for DSI AT2 5.1 Title, name, student number etc 5.2 Introduction 5.3 Description of process, or method 5.4 Analysis 5.5 Findings and conclusions 5.6 Discussion 5.7 Reflection 5.8 References 5.9 Appendices 5.10 Other 5.11 The ODI Canvas", " 5 Simplified (very) Template for DSI AT2 This is the template, or structure for the report. Make sure that you read it closely, several times. Word length 2800 words (excluding data excerpts and appendices, visualisations, and references). Citations In this assignment, use footnotes to do citation. Heres how to do it.1 Embedding an image If you want to embed an image, such as this UTS logo which is in the same directory as this .Rmd file, heres some code that shows you how to do it: Structure This is the suggested structure for your report. The basic structure is similar to the style of academic papers and, if followed, should ensure that everything you need to include is present. I have included the assessment criteria at the relevant places to remind you of what needs to be in the report. You are free to vary the structure by renaming the sections, including other sections, or dropping ones that you dont use. Keep in mind that the suggested structure is conventional (and therefore easy to follow), practical, and comprehensive. (Criterion 5: Professionally presented in a manner appropriate to the discipline.) Note: The text between the angle brackets, &lt; &gt;, below, is replaced by your text. 5.1 Title, name, student number etc 5.2 Introduction &lt;a paragraph that gives an overview of what youve done&gt; 5.3 Description of process, or method &lt;this is where you give details about what youve been collecting and how much you data have; why you choose this data to collect; how you managed the quality and frequency of collection issues; what you did to anonymise or de-identify the data, and how you dealt with the storage and sharing of data within the group. Do not include a dump of all your data here. If you wish to include examples of data (and I think you should) then put these in an appendix to the report. Criterion 1: Justifies a method to obtain data from multiple sources, for gaining insight into a chosen problem, including analysis of data quality issues in the individual and group data. &gt; 5.4 Analysis &lt;describe how you analysed your data, and how you contrasted your data with the groups data. Criterion 2: Justifies the analysis of the obtained data, including quality issues, to draw conclusions in a professional and engaging manner. You should include your analysis here using R code, or by loading images and tables youve saved from other programs, like this.&gt; Or like this: 5.5 Findings and conclusions &lt;what conclusions did you come to as a result of the analysis of your data and of the groups data. Criterion 2: Justifies the analysis of the obtained data, including quality issues, to draw conclusions in a professional and engaging manner.&gt; 5.6 Discussion &lt;discuss aspects of the process that you see as important. For example, what difficulties did you encounter; how could you avoid problems if you did it again; etc&gt; Your justification and evaluation of your approach is likely to go in this section, but may also be threaded through the preceding sections. This includes Criterion 3: Identifies, contextualises, and reflects on the ethical, privacy, and legal issues relevant to the collection and analysis of personal data of self and others. &gt; 5.7 Reflection &lt;General reflection on what you learnt during this task. What are you unsure about? What would you do differently if you had to do it all again? How do these experiences relate to the wider practice of data science (for example, issues with collecting, cleaning, analysing and deriving meaning from data, and the ethics of this)? Criteria 4: Connects the individual experience of this QS project to the practice of data science (and the preceding three criteria).&gt; 5.8 References &lt;include any cited references, formatted in Harvard style.&gt; 5.9 Appendices &lt;include samples of your data - enough to give a sense of what your raw data looks like&gt; 5.10 Other If you are submitting any additional materials, such as short multimedia presentations or visualisations (such as Prezi, or voice-over video/screen capture, etc), they probably cant be submitted through Canvas so you will need to arrange some other process such as posting on YouTube or elsewhere, or handing in a memory stick. Please ensure that additional material like this is accessible to the markers (test this by accessing it through someone elses computer) and avoid any restrictive or proprietary software constraints. Remember to check any included web links! Diagrams, figures, charts and illustrations must be labelled, and explained, and must be referred to from somewhere in the report. If drawn from another source, then the source must be provided. 5.11 The ODI Canvas You can download it and include it like this (play around with the settings to make it display sensibly). You can also include it as a html file, etc. This is the text of the footnote which you can see at the bottom of the page. "],["simplified-template-for-dsi-at2.html", "6 Simplified Template for DSI AT2 6.1 Preface: How to use this guide 6.2 Set up a project 6.3 Install packages 6.4 Calculating word length 6.5 Citations 6.6 Formatting guide 6.7 Embedding an image 6.8 Introduction 6.9 Description of process or methods 6.10 Analysis 6.11 Findings and conclusion 6.12 Discussion 6.13 Reflection 6.14 References 6.15 Appendices 6.16 Other", " 6 Simplified Template for DSI AT2 6.1 Preface: How to use this guide This document has a suggested structure for your report, starting from section 1 Introduction. Before that, we have some tutorials on how to set up your environment, which you can delete once youve read so you dont hand them in. The basic structure of this template is similar to the style of academic papers and, if followed, should ensure that everything you need to include is present. I have included the assessment criteria at the relevant places to remind you of what needs to be in the report. You are free to vary the structure by renaming the sections, including other sections, or dropping ones that you dont use. Keep in mind that the suggested structure is conventional (and therefore easy to follow), practical, and comprehensive. (Criterion 5: Professionally presented in a manner appropriate to the discipline.) If you do use this template, you will need to install R, RStudio, and the packages listed in the code block at the head of this document. Note: We have provided some sample code below, along with some text between angle brackets, &lt; &gt;. All of this should be replaced by your work. Please dont forget to include a title, name, student number, etc. on a covering sheet 6.2 Set up a project It is best to set up your assignment as a project, rather than just have a single RMarkdown file. Setting up a project will define your working directory based on where a .RProj file is located. Other files and folders can then be found relative to that .RProj file. This gives projects some advantages: - Its easier to find your files, because you can set up subfolders with consistent names - You can refer to your data with relative referencing, eg ../datamy_data.csv, rather than having to type C:\\folder\\other_folder\\data\\my_data.csv. - When you open your project, it unloads your libraries and clears your memory. That way, the libraries that you had loaded before wont get in the way of the one youre working on now. But when you close this project, it goes back to the state it was in before. To start a project in RStudio, - click File -&gt; New Project and follow the prompts to set up a new project in a new folder. - Create subfolders called R and data. - Save this template to the R folder, along with any other R code files you create on the project. - Save any data files (eg csv files, or screenshots from your other analysis) to the data folder. I highly recommend this link on project-oriented workflow 6.3 Install packages If we dont have these packages, well need to download them from the internet. Heres some code that does that. The code is currently commented out (that is, it has a # at the start of the line.) Remove the # if you want to install those packages. # install.packages(c(&quot;tidyverse&quot;, &quot;here&quot;, &quot;knitr&quot;)) # devtools::install_github(&quot;benmarwick/wordcountaddin&quot;, # type = &quot;source&quot;, # dependencies = TRUE) ## Go to Tools &gt; Addins &gt; Browse Addins, and then search for wordcountaddin. ## There will be two. Click them one at a time and click the Execute button. Now, test the file by using the knit button (just above this code chunk). Read more about R markdown and kniting (rendering) documents here: https://rmarkdown.rstudio.com/authoring_quick_tour.html#overview Installing the packages only puts them on our computer. To use them in our project, we need them loaded. # Load libraries library(psych) library(devtools) library(tidyverse) library(here) library(knitr) library(bookdown) #supercedes the kfigr tool below, which is a bit ropey #library(kfigr) #this lets us crossreference figures, etc. Read more about it #at https://github.com/mkoohafkan/kfigr/edit/master/vignettes/introduction.Rmd 6.4 Calculating word length The word limit is 2800 words (excluding data excerpts and appendices, visualisations, and references) To check this, you can either copy the html output to word, or use the addin Word Count Addin. E.g. wordcountaddin:::text_stats() 6.5 Citations In this assignment, well use footnotes to do citation. Heres how to do it.2 6.6 Formatting guide Here are some formatting tricks you can use. 6.6.1 Fonts italics bold bold italics verbatim code superscript2 subscript2 This is a block quotation, if you have a long quote from someone this is the best way to do it (but dont forget the citation). This is a very long line that will still be quoted properly when it wraps. Oh boy lets keep writing to make sure this is long enough to actually wrap for everyone. Oh, you can put Markdown into a blockquote. 6.6.2 Headings Add headings using a # (but note, to get that to display properly I had to escape it using a preceding backslash). One # gives you a line with Heading 1 style, ## gives you Heading 2 etc. 6.6.3 Lists Numbered Lists Are Possible And so are bulleted lists More examples can be found on the cheat sheet at this hyperlink 6.6.4 Equations If you want to insert equations (you probably dont) you can do so using the syntax below. You can also insert bits of inline code like, so the 2+2 here is produced by a piece of code, and the 4 is produced by an equation (namely 2+2) The deterministic part of the model is defined by this in-line equation as \\(\\mu_i = \\beta_0 + \\beta_1x\\), and the stochastic part by the centered equation: \\[ \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-(x-\\mu_i)^2/(2\\sigma^2)} \\] More examples at this hyperlink 6.7 Embedding an image You might have saved some analysis from another program as a picture file. This is how you paste it: Lets embed a UTS logo, which Ive saved to the data folder. 6.8 Introduction &lt; Write a paragraph that gives an overview of what youve done. Also, make sure to include the assignment title, your name, and student number in rows 2 to 4 at the top of the page in RMarkdown. &gt; 6.9 Description of process or methods &lt;this is where you give details about what youve been collecting and how much you data have; why you choose this data to collect; how you managed the quality and frequency of collection issues; what you did to anonymise or de-identify the data, and how you dealt with the storage and sharing of data within the group. Do not include a dump of all your data here. If you wish to include examples of data (and I think you should) then put these in an appendix to the report. Criterion 1: Justifies a method to obtain data from multiple sources, for gaining insight into a chosen problem, including analysis of data quality issues in the individual and group data.&gt; 6.10 Analysis &lt;describe how you analysed your data, and how you contrasted your data with the groups data. Criterion 2: Justifies the analysis of the obtained data, including quality issues, to draw conclusions in a professional and engaging manner.&gt; 6.10.1 Example analysis: Get data If you downloaded the full folder, then the csv files you need are there. You can also get your own weather data if you want. library(tidyverse) library(here) # Load a csv file from our hard drive # weather_sydney &lt;- read_csv(here::here(&quot;data&quot;, &quot;syd_weath.csv&quot;)) # weather_melbourne &lt;- read_csv(here::here(&quot;data&quot;, &quot;mel_weath.csv&quot;)) weather_sydney &lt;- read_csv(&quot;data/templates/syd_weath.csv&quot;) weather_melbourne &lt;- read_csv(&quot;data/templates/mel_weath.csv&quot;) # Load an Excel file from our hard drive # sydney_xl &lt;- readxl::read_excel(path = here::here(&quot;data&quot;, &quot;syd_weath.xls&quot;)) sydney_xl &lt;- readxl::read_excel(path = (&quot;data/templates/syd_weath.xls&quot;)) # Simulate our own data - 5 rows and 2 columns my_fake_data1 &lt;- tibble(first_column = c(1, 1, 2, 1, 1), second_column = c(&quot;a&quot;, &quot;b&quot;, &quot;a&quot;, &quot;a&quot;, &quot;b&quot;), ) #Simulate normally distributed data my_fake_data2 &lt;- tibble(normal_column = rnorm(n = 50, mean = 0, sd = 1), higher_column = rnorm(n = 50, mean = 0.1, sd = 1), lower_column = rnorm(n = 50, mean = -0.1, sd = 1) ) 6.10.2 Example analysis: Explore data #Explore using base R techniques head(weather_sydney) # First few rows of the weather_sydney table ## # A tibble: 6 x 22 ## X1 date temp dew_pt hum wind_spd wind_gust dir vis ## &lt;dbl&gt; &lt;dttm&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1 2018-02-08 00:00:00 23 15 52 16.7 NA North 30 ## 2 2 2018-02-08 00:00:00 23 15 61 16.7 NA North NA ## 3 3 2018-02-08 00:30:00 22 15 64 13 NA NNW NA ## 4 4 2018-02-08 01:00:00 22 15 56 11.1 NA NNW NA ## 5 5 2018-02-08 01:00:00 22 15 64 11.1 NA NNW NA ## 6 6 2018-02-08 01:30:00 22 15 64 13 NA North NA ## # ... with 13 more variables: pressure &lt;dbl&gt;, wind_chill &lt;lgl&gt;, ## # heat_index &lt;dbl&gt;, precip &lt;lgl&gt;, precip_rate &lt;lgl&gt;, precip_total &lt;lgl&gt;, ## # cond &lt;chr&gt;, fog &lt;dbl&gt;, rain &lt;dbl&gt;, snow &lt;dbl&gt;, hail &lt;dbl&gt;, thunder &lt;dbl&gt;, ## # tornado &lt;dbl&gt; dim(weather_sydney) # Number of rows and columns ## [1] 2206 22 colnames(weather_sydney) #Column names ## [1] &quot;X1&quot; &quot;date&quot; &quot;temp&quot; &quot;dew_pt&quot; &quot;hum&quot; ## [6] &quot;wind_spd&quot; &quot;wind_gust&quot; &quot;dir&quot; &quot;vis&quot; &quot;pressure&quot; ## [11] &quot;wind_chill&quot; &quot;heat_index&quot; &quot;precip&quot; &quot;precip_rate&quot; &quot;precip_total&quot; ## [16] &quot;cond&quot; &quot;fog&quot; &quot;rain&quot; &quot;snow&quot; &quot;hail&quot; ## [21] &quot;thunder&quot; &quot;tornado&quot; #Explore using techniques from the tidyverse package glimpse(weather_sydney) # Does all of the above base R techniques, but neater ## Rows: 2,206 ## Columns: 22 ## $ X1 &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17~ ## $ date &lt;dttm&gt; 2018-02-08 00:00:00, 2018-02-08 00:00:00, 2018-02-08 00:~ ## $ temp &lt;dbl&gt; 23, 23, 22, 22, 22, 22, 22, 22, 22, 21, 21, 21, 21, 21, 2~ ## $ dew_pt &lt;dbl&gt; 15, 15, 15, 15, 15, 15, 16, 16, 15, 15, 15, 15, 15, 15, 1~ ## $ hum &lt;dbl&gt; 52, 61, 64, 56, 64, 64, 60, 69, 64, 62, 68, 68, 62, 68, 7~ ## $ wind_spd &lt;dbl&gt; 16.7, 16.7, 13.0, 11.1, 11.1, 13.0, 11.1, 11.1, 11.1, 9.3~ ## $ wind_gust &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~ ## $ dir &lt;chr&gt; &quot;North&quot;, &quot;North&quot;, &quot;NNW&quot;, &quot;NNW&quot;, &quot;NNW&quot;, &quot;North&quot;, &quot;NNW&quot;, &quot;N~ ## $ vis &lt;dbl&gt; 30, NA, NA, NA, NA, NA, NA, NA, NA, 30, NA, NA, NA, NA, N~ ## $ pressure &lt;dbl&gt; 1020, 1020, 1020, 1020, 1020, 1019, 1020, 1019, 1019, 101~ ## $ wind_chill &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~ ## $ heat_index &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~ ## $ precip &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~ ## $ precip_rate &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~ ## $ precip_total &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~ ## $ cond &lt;chr&gt; &quot;Partly Cloudy&quot;, &quot;Clear&quot;, &quot;Clear&quot;, NA, &quot;Clear&quot;, &quot;Clear&quot;, ~ ## $ fog &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~ ## $ rain &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~ ## $ snow &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~ ## $ hail &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~ ## $ thunder &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~ ## $ tornado &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~ #Explore by creating histograms hist(weather_sydney$temp, main = &quot;Sydney weather&quot;, xlab = &quot;Temp&quot;) hist(weather_melbourne$temp, main = &quot;Melbourne weather&quot;, xlab = &quot;Temp&quot;) #Explore by creating scatterplots plot(x = weather_sydney$date, y = weather_sydney$temp, xlab = &quot;Dates&quot;, ylab = &quot;Temperature&quot;, main = &quot;Sydney Temperatures in February and March&quot; ) #Category counts table(weather_sydney$cond) # Count of each condition ## ## Clear Drizzle ## 285 3 ## Haze Heavy Rain Showers ## 63 2 ## Light Drizzle Light Rain ## 11 40 ## Light Rain Showers Light Thunderstorms and Rain ## 72 5 ## Mostly Cloudy Overcast ## 591 27 ## Partly Cloudy Rain ## 362 10 ## Rain Showers Scattered Clouds ## 13 247 ## Thunderstorm Unknown ## 1 4 prop.table(table(weather_sydney$cond)) * 100 # Percentage of each condition ## ## Clear Drizzle ## 16.41705069 0.17281106 ## Haze Heavy Rain Showers ## 3.62903226 0.11520737 ## Light Drizzle Light Rain ## 0.63364055 2.30414747 ## Light Rain Showers Light Thunderstorms and Rain ## 4.14746544 0.28801843 ## Mostly Cloudy Overcast ## 34.04377880 1.55529954 ## Partly Cloudy Rain ## 20.85253456 0.57603687 ## Rain Showers Scattered Clouds ## 0.74884793 14.22811060 ## Thunderstorm Unknown ## 0.05760369 0.23041475 # 6.10.3 Example Analysis: Explore data via statistical summaries kable(rbind(psych::describe(weather_sydney$temp), psych::describe(weather_melbourne$temp)), caption = &quot;Summary of Mel &amp; Sydney weather&quot;) Table 6.1: Summary of Mel &amp; Sydney weather vars n mean sd median trimmed mad min max range skew kurtosis se X1 1 2206 23.37307 3.006867 23.0 23.16025 2.9652 17 39.0 22.0 1.097941 2.9843386 0.0640194 X11 1 1562 23.01485 5.097803 22.8 22.73952 5.9304 13 40.4 27.4 0.475591 -0.2072643 0.1289860 #note, you should label the rows Youll see above that I used a labelled the table, I did that by using the chunk name, and type like this: \\@ref(tab:Summaryweather. Now, I can use that to refer to it like this 6.1 Of course, you dont have to just display the correlation, you can **output the coefficient in-line with code: 0.6514409* 6.10.4 Example analysis: Tidy data To tidy data is to prepare it for analysis. The tidyverse package includes a package called dplyr which does this very well. Here are some examples #Combine the two weather data sets by putting the rows on top of each other weather_combined &lt;- weather_sydney %&gt;% rbind(weather_melbourne) # Select just three of the columns weather_combined &lt;- weather_combined %&gt;% select(date, temp, hum) # Filter so that you only have rows where temperature &gt; 28 degrees and humidity &gt; 50% weather_combined &lt;- weather_combined %&gt;% filter(temp &gt; 28, hum &gt; 50 ) # Mutate (add a new column) that adds temperature and humidity weather_combined &lt;- weather_combined %&gt;% mutate(my_weird_column = temp + hum) # Do everything again, but in one long piece of tidying weather_combined &lt;- weather_sydney %&gt;% rbind(weather_melbourne) %&gt;% select(date, temp, hum) %&gt;% filter(temp &gt; 28, hum &gt; 50) %&gt;% mutate(my_weird_column = temp + hum) # For more types of tidying to add to a chain like this, google dplyr tutorials #Look at what we have wrought! weather_combined ## # A tibble: 46 x 4 ## date temp hum my_weird_column ## &lt;dttm&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2018-02-10 15:00:00 29 55 84 ## 2 2018-02-10 15:30:00 29 55 84 ## 3 2018-02-14 10:30:00 29 62 91 ## 4 2018-02-14 11:00:00 29 58 87 ## 5 2018-02-15 15:30:00 29 51 80 ## 6 2018-02-15 16:00:00 29 55 84 ## 7 2018-02-18 11:30:00 29 58 87 ## 8 2018-02-18 12:30:00 29 55 84 ## 9 2018-02-18 13:00:00 29 55 84 ## 10 2018-02-18 13:30:00 29 58 87 ## # ... with 36 more rows 6.10.5 Example analysis: Create charts for presentation ggplot2 is a library that adds analysis one layer at a time, giving you a lot more control over what you want to see. This can make it a better tool for making charts designed to communicate ideas with your audience, rather than the standard charts that we used before. To explore the philosophy behind ggplot2, and get links to galleries and cheat sheets, go to click this hyperlink. #Get data temp &lt;- weather_sydney %&gt;% mutate(loc = &quot;Syd&quot;) %&gt;% rbind(weather_melbourne %&gt;% mutate(loc = &quot;Mel&quot;)) %&gt;% select(temp, loc) #Make chart ggplot(temp, aes(x = temp, fill = loc)) + geom_histogram(alpha = .5, aes(y = ..density..), position = &#39;identity&#39; ) 6.11 Findings and conclusion &lt;what conclusions did you come to as a result of the analysis of your data and of the groups data. Criterion 2: Justifies the analysis of the obtained data, including quality issues, to draw conclusions in a professional and engaging manner.&gt; 6.12 Discussion &lt;discuss aspects of the process that you see as important. For example, what difficulties did you encounter; how could you avoid problems if you did it again; etc&gt; Your justification and evaluation of your approach is likely to go in this section, but may also be threaded through the preceding sections. This includes Criterion 3: Identifies, contextualises, and reflects on the ethical, privacy, and legal issues relevant to the collection and analysis of personal data of self and others. &gt; 6.13 Reflection &lt;General reflection on what you learnt during this task. What are you unsure about? What would you do differently if you had to do it all again? Criteria 4: Connects the individual experience of this QS project to the practice of data science (and the preceding three criteria). &gt; 6.14 References &lt;include any cited references, formatted in Harvard style.&gt; 6.15 Appendices &lt;include samples of your data - enough to give a sense of what your raw data looks like&gt; 6.16 Other If you are submitting any additional materials, such as short multimedia presentations or visualisations (such as Prezi, or voice-over video/screen capture, etc), they probably cant be submitted through canvas so you will need to arrange some other process such as posting on YouTube or elsewhere, or handing in a memory stick. Please ensure that additional material like this is accessible to the markers (test this by accessing it through someone elses computer) and avoid any restrictive or proprietary software constraints. Remember to check any included web links! Diagrams, figures, charts and illustrations must be labelled, and explained, and must be referred to from somewhere in the report. If drawn from another source, then the source must be provided. In the template file, this line (wrapped in ``) is used to insert the references. Testing to see if just using the heading works, with a hash before the reference. r if (knitr::is_html_output())  References {-} This is the text of the footnote which you can see at the bottom of the page. "],["references-2.html", "7 References", " 7 References "]]
